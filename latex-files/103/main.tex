\documentclass[12pt]{amsart}
\usepackage[russian]{babel}
\usepackage{longtable}
\usepackage{array}
\usepackage{verbatim}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{floatflt}
\usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{textcomp}
%\documentclass[12pt]{amsart}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[russian]{babel}
\usepackage{longtable}
\usepackage{array}
\usepackage{verbatim}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{floatflt}
\usepackage{wrapfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{textcomp}
\usepackage{listings}
\usepackage{color}
%\extrarowheight 6pt
\textwidth  17,5cm  \textheight 25cm
\topmargin  -18mm  \oddsidemargin  -8mm \evensidemargin -8mm
%\newcommand\prt{\partial}
%\newcommand\bfx{\mathbf x}
%\newcommand\bfy{\mathbf y}
%\newcommand{\circledx}{{\overset{\circ}{x}}}
\pagestyle{empty}
\begin{document}
\large
\thispagestyle{empty}
\centerline{\bf Лабораторная работа 4 по МВМ}
\centerline{\bf Моисеев Дмитрий А--14--21}
Рассматривается задача конвекции - диффузии:\\
\begin{center}
\begin{cases}
	$-\dfrac{\partial}{\partial x} \left(k_1(x, y, u) \dfrac{\partial u}{\partial x}\right)-\dfrac{\partial}{\partial y} \left(k_2(x, y, u) \dfrac{\partial u}{\partial y}\right)+v_1\dfrac{\partial u}{\partial x} + v_2\dfrac{\partial u}{\partial y} = f$\\
	$u\big|_{\partial\Omega} = g$
\end{cases}\\
\end{center}
в прямоугольной области $\Omega = \{ (x,y)\in \mathbb{R}^{2}|0<x<X,0<y<Y} \}$\\
Здесь $v=(v_1(x,y, u),v_2(x,y, u))^T$ - заданный вектор скорости.\\
Заменим область $\Omega$ конечномерной сеткой, а производные  их разностными аппроксимациями. В результате получим систему уравнений:\\
$-\bigg(L_x(i, j, u) + L_y(i, j, u)\bigg) + D_x(i, j, u) + D_y(i, j, u) = f(i \cdot h_x, j \cdot h_y, u)$ 
где операторы определены следующим образом:
\begin{align*}
L_x(i, j, u) &= \dfrac{a_x(i+1, j, u) \cdot (u[i+1,j] - u[i,j]) - a_x(i, j, u) \cdot (u[i,j] - u[i-1,j])}{h_x^2}, \\
L_y(i, j, u) &= \dfrac{a_y(i, j+1, u) \cdot (u[i,j+1] - u[i,j]) - a_y(i, j, u) \cdot (u[i,j] - u[i,j-1])}{h_y^2}, \\
a_x(i, j, u) &= \dfrac{k_1(i \cdot h_x, j \cdot h_y, u[i,j]) + k_1((i-1) \cdot h_x, j \cdot h_y, u[i-1,j])}{2}, \\
a_y(i, j, u) &= \dfrac{k_2(i \cdot h_x, j \cdot h_y, u[i,j]) + k_2(i \cdot h_x, (j-1) \cdot h_y, u[i,j-1])}{2}.
\end{align*}


для узлов внутри области\\
Используем разности против потока:\\
\begin{center}
$D_xu_{ij} = \dfrac{1}{h_x}$
\begin{cases}
$u_{ij}-u_{i-1,j}$, если v_{1ij}>0,\\
$u_{i+1,j}-u_{i,j}$, если v_{1ij}<0,\\
\end{cases}\\
$D_yu_{ij} = \dfrac{1}{h_y}$
\begin{cases}
$u_{ij}-u_{i,j-1}$, если v_{2ij}>0,\\
$u_{i,j+1}-u_{i,j}$, если v_{2ij}<0,\\
\end{cases}\\
\end{center}

\section{Постановка задачи}

Рассматриваем задачу, решаемую методом Ньютона-Крылова (JFNK), где требуется решение системы нелинейных уравнений вида:222ee

\[
F(p) = 0
\]

где \( p \) — это вектор неизвестных, а \( F(p) \) — это нелинейная функция, зависящая от \( p \). Метод Ньютона-Крылова используется для приближенного решения данной системы, где на каждом шаге аппроксимируем нелинейную задачу линейной системой.

\section{Линеаризация задачи}

Метод Ньютона для решения нелинейной задачи предполагает линейную аппроксимацию функции в текущей точке \( p_{\text{solv}} \):

\[
F(p) \approx F(p_{\text{solv}}) + J(p_{\text{solv}}) \cdot (p - p_{\text{solv}})
\]

где \( J(p_{\text{solv}}) \) — это якобиан функции \( F(p) \) в точке \( p_{\text{solv}} \), а \( p \) — это новый вектор, который мы ищем.

Предположим, что \( F(p_{\text{solv}}) \) уже вычислено, и нам нужно решить систему линейных уравнений для обновления вектора \( p \):

\[
J(p_{\text{solv}}) \cdot \Delta p = -F(p_{\text{solv}})
\]

где \( \Delta p \) — это шаг для обновления решения.

\section{Упрощение задачи с использованием метода Ньютона-Крылова}

Вместо явного вычисления якобиана и решения линейной системы с использованием полной матрицы \( J(p_{\text{solv}}) \), в методах Ньютона-Крылова используется так называемая "свободная форма Якоби" (Jacobian-free), что означает, что матрица якобиана не вычисляется напрямую. Вместо этого задача сводится к вычислению оператора \( J(p_{\text{solv}}) \cdot v \) для некоторого вектора \( v \) через умножение на аппроксимированную матрицу оператора.

Таким образом, задача на каждом шаге сводится к решению следующей линейной системы:

\[
A(p_{\text{solv}}) \cdot \Delta p = -F(p_{\text{solv}})
\]

где \( A(p_{\text{solv}}) \) представляет собой аппроксимированную матрицу системы, зависящую от текущего решения \( p_{\text{solv}} \), а \( F(p_{\text{solv}}) \) — это вектор невязки.

\section{Применение метода BiCGStab}

Теперь задача сводится к решению линейной системы с использованием метода BiCGStab. Он решает систему уравнений вида:

\[
A \cdot x = b
\]

где \( A \) — это матрица системы (в нашем случае, оператор \( A(p_{\text{solv}}) \), зависящий от текущего приближения \( p_{\text{solv}} \)), а \( b \) — вектор правой части (в данном случае, это \( -F(p_{\text{solv}}) \)).

\newpage
Находим решение задачи с помощью метода Ньютона-Крылова.\\
\begin{center}
\textit{Примеры:}
\end{center}
1) искомое решение $u(x,y)=x+100y+10000$\\
$v_1(x, y) = 0, v_2(x, y) = 0$\\
$k_1(x, y, u) = 1, k_2(x, y, u) = 1$\\
$f(x,y)=0$\\
$X = 0.1, Y = 0.1$ - размеры области\\
\begin{tabular}{|c|c|c|}
\hline
N_x,N_y & Погрешность & Время \\
\hline
 10   &  0.0146    & 0.0420   \\
\hline
 20   &  0.0312   & 0.5607  \\
\hline
 40   &   0.0642  & 5.9445 \\
\hline
 80   &  0.1302  & 59.6068  \\        
\hline
\end{tabular}\\
\includegraphics[scale=0.6]{Num_1.png} \\
2) искомое решение $u(x,y)=\pi * \cos(x) * \sin(x*y)$\\
$f(x,y) = \pi \left( \cos(y) \sin(xy) \left( 1 + x y^2 \right) + x \left( 2 \sin(y) \cos(xy) + \cos(y) x \sin(xy) \right) - \sin(y) \sin(xy) + \cos(y) x \cos(xy) \right)$\\
$v_1(x, y) = 0, v_2(x, y) = 0$\\
$k_1(x, y, u) = x, k_2(x, y, u) = 1$\\
$X = 2, Y = 2$ \\
\begin{tabular}{|c|c|c|}
\hline
N_x,N_y & Погрешность & Время \\
\hline
 10   &  0.0921    & 0.1806   \\
\hline
 20   &  0.0438   & 1.9751  \\
\hline
 40   &   0.0214  & 20.5081 \\
\hline
 80   &  0.0105  & 264.7923  \\        
\hline
\end{tabular}\\
\includegraphics[scale=0.6]{Num_2.png} \\

3) искомое решение $u(x,y)=x^2 + y^2$\\
$f(x,y) = -2*(1+(x^2+y^2)*(5*x^2+y^2)-y^2)$\\
$v_1(x, y) = 0, v_2(x, y) = y$\\
$k_1(x, y, u) = u^2, k_2(x, y, u) = 1$\\
$X = 0.5, Y = 0.5$ \\
\begin{tabular}{|c|c|c|}
\hline
N_x,N_y & Погрешность & Время \\
\hline
 10   &  1.2054e-09    & 0.1484  \\
\hline
 20   &  1.1837e-09   & 1.6593  \\
\hline
 40   &   2.6071e-09  & 14.6416 \\
\hline
 80   &  0.3232  & 589.6798  \\        
\hline
\end{tabular}\\
\includegraphics[scale=0.6]{Num_3.png} \\
код функции метода Ньютона-Крылова:
% Define custom colors
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codeblue}{rgb}{0,0,0.9}
% Set up the listings package
\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{codeblue},
    commentstyle=\color{codegreen},
    stringstyle=\color{codegray},
    numbers=left,
    numberstyle=\tiny\color{codegray},
    stepnumber=1,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    breaklines=true,
    backgroundcolor=\color{white},
    frame=single,
    inputencoding=utf8
}
\begin{lstlisting}
def solve_jfnk(p_solv, tol=1e-5, max_iter=100):
    delta = solve_bicgstab_jfnk(-Au(p_solv), p_solv)
    p_solv += delta
    for k in range(max_iter):
        if np.linalg.norm(delta) < tol:
            break
        #print(p_solv)
        delta = solve_bicgstab_jfnk(-Au(p_solv), p_solv, tol)
        p_solv += delta
        print(np.linalg.norm(p_solv))

    return p_solv
    
def solve_bicgstab_jfnk(b, p_solv, tol=1e-5, max_iter=1000):
    x = np.zeros_like(b)
    #print(b, apply_jacobian_free(p_solv, x), sep="\n\n")
    r = b - Ad(p_solv, x)

    r0_hat = r.copy()
    rho_old = alpha = omega = 1.0
    v = p = np.zeros_like(b)

    for iteration in range(max_iter):
        rho_new = sc_mult(r0_hat, r)
        if abs(rho_new) < 1e-10:
            print(f"Interrupt: rho_new is too small.")
            break
        if iteration == 0:
            p = r.copy()
        else:
            #print(f"rho_old = {rho_old}, omega = {omega}")
            beta = (rho_new / rho_old) * (alpha / omega)
            p = r + beta * (p - omega * v)

        v = Ad(p_solv, p)
        alpha = rho_new / sc_mult(r0_hat, v)
        s = r - alpha * v   

        if np.linalg.norm(s) < tol:
            x += alpha * p
            print(f"It came together for {iteration + 1} iteration.")
            break

        t = Ad(p_solv, s)
        omega = sc_mult(t, s) / sc_mult(t, t)

        x += alpha * p + omega * s
        r = s - omega * t

        if np.linalg.norm(r) < tol:
            break

        rho_old = rho_new

    return x
    
def Ad(x, w, h=1e-8):
    norm_x = np.linalg.norm(x)
    norm_w = np.linalg.norm(w)

    if norm_x != 0 and norm_w != 0:
        delta = h * norm_x / norm_w
        return (Au(x + delta * w) - Au(x)) / delta
    elif norm_x == 0 and norm_w != 0:
        delta = h / norm_w
        return (Au(delta * w) - Au(np.zeros_like(x))) / delta
    elif norm_x == 0 and norm_w == 0:
        return np.zeros_like(w)
    else:
        return np.zeros_like(w)
\end{lstlisting} 


\section{Вывод}

\subsection{Нелинейность уравнений}
Эта задача включает решение нелинейной системы уравнений, где зависимость от переменных и параметров имеет нелинейный характер. Метод Ньютона-Крылова эффективен для таких задач, так как он позволяет на каждом шаге линейно аппроксимировать нелинейные уравнения с использованием итерационного процесса. Это позволяет избегать явного вычисления полной матрицы Якоби и позволяет работать с операторами, зависящими от текущего приближения решения, что делает метод особенно удобным в контексте нелинейных задач.

\subsection{Скорость сходимости}
Метод Ньютона-Крылова обладает хорошей сходимостью, особенно для задач, где начальные приближения близки к точному решению. В моих примерах можно заметить, что при увеличении числа узлов ($N_x$, $N_y$) погрешность уменьшается, но время решения растет пропорционально размеру задачи. Однако благодаря использованию метода BiCGStab (который является частью алгоритма Ньютона-Крылова) можно эффективно решать возникающие линейные системы на каждом шаге, что значительно улучшает общую эффективность решения.

\subsection{Экономия памяти и вычислительных ресурсов}
Одним из преимуществ метода Ньютона-Крылова является возможность работы с так называемой "свободной формой Якоби" (Jacobian-free), что позволяет избегать хранения и вычисления полного Якобиана системы. Это критично для больших и сложных задач, где размерность системы может быть очень большой, и хранение полной матрицы Якоби может быть невозможно или неэффективно.


\vskip 30pt






\end{document}



